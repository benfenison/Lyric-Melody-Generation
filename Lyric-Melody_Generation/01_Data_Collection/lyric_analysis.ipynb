{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Using Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lyricsgenius\n",
      "  Using cached lyricsgenius-3.0.1-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/benjaminfenison/opt/anaconda3/lib/python3.9/site-packages (from lyricsgenius) (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /Users/benjaminfenison/opt/anaconda3/lib/python3.9/site-packages (from lyricsgenius) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/benjaminfenison/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/benjaminfenison/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/benjaminfenison/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/benjaminfenison/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/benjaminfenison/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (2.0.4)\n",
      "Installing collected packages: lyricsgenius\n",
      "Successfully installed lyricsgenius-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import lyricsgenius as genius #used to interface with Genius API\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias client_access_token\n"
     ]
    }
   ],
   "source": [
    "#token provided by Genius API\n",
    "%store -r client_access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_access_token = 'qqoXje06ERBkSJz9qtBBl1HzJyLoxuC51bU2bftPjMgS1XnkUeyVQ5_9ZNjvL6g7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initiate Genius\n",
    "genius = genius.Genius(client_access_token)\n",
    "genius.verbose = False #turn off status messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(track,artist):\n",
    "    '''\n",
    "    function returns song's lyrics\n",
    "    parameters:\n",
    "        track-->str\n",
    "        artist-->str\n",
    "    '''\n",
    "    track = re.sub(' - .+','',track) #remove text after '-'\n",
    "    track = re.sub(' \\(.*\\)','',track) #remove text within parentheses\n",
    "    track = re.sub(' \\[.*\\]','',track) #remove text within brackets\n",
    "    \n",
    "    try:\n",
    "        return genius.search_song(track,artist).lyrics\n",
    "    except:\n",
    "        print(track + ' by ' + artist + ' is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_songs(track_list,artist_list):\n",
    "    '''\n",
    "    function obtains lyrics and returns dataframe with columns for track, artist, lyrics\n",
    "    parameters:\n",
    "        track_list-->list of str \n",
    "        artist_list-->list of str\n",
    "    '''\n",
    "    lyrics_list = [get_lyrics(track_list[x],artist_list[x]) for x in range(len(track_list))] #get lyrics for each song\n",
    "    \n",
    "    return pd.DataFrame(data={'track':track_list,'artist':artist_list,'lyrics':lyrics_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(df,col,new_col):\n",
    "    '''\n",
    "    function returns dataframe with new column of cleaned text (song lyrics)\n",
    "    parameters:\n",
    "        df-->pandas dataframe\n",
    "        col-->column to clean (str)\n",
    "        new_col-->name of column with cleaned text (str)\n",
    "    '''\n",
    "    df[new_col] = df[col].str.lower() #make all text lowercase\n",
    "    df[new_col] = df[new_col].str.replace(r'\\n',' ') #replace '\\n' character with space\n",
    "    df[new_col] = df[new_col].str.replace(r'\\[[^\\[\\]]*]','') #remove brackets and inside text\n",
    "    df[new_col] = df[new_col].str.replace(r\"\\'\\w*\",'').str.replace(r'[^\\w\\d\\s]+','') #remove extra characters\n",
    "    df[new_col] = df[new_col].str.strip() #remove extra whitespace\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lyrics(df,col):\n",
    "    '''\n",
    "    function returns dataframe with column as list of words\n",
    "        tokenizes, removes stopwords from, and lemmatizes lyrics\n",
    "    parameters:\n",
    "        df-->pandas dataframe\n",
    "        col-->column to normalize\n",
    "    '''\n",
    "\n",
    "    df[col] = df[col].str.split() #tokenize lyrics\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df[col] = df[col].apply(lambda row: [w for w in row if w not in stop_words]) #remove stopwords\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize_text(text):\n",
    "        '''\n",
    "        function returns lemmatized text\n",
    "        parameters:\n",
    "            text-->str\n",
    "        '''\n",
    "        return [lemmatizer.lemmatize(w) for w in text]\n",
    "    \n",
    "    df[col] = df[col].apply(lemmatize_text) #lemmatize words\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def segmenting(s):\n",
    "    s = s.replace('\\n',' ')\n",
    "    structures = re.findall(r'\\[.*?\\]', s)\n",
    "    iter = re.finditer(r'\\[.*?\\]', s)\n",
    "    indices = [m.start(0) for m in iter]\n",
    "    splits = []\n",
    "    for i in range(len(indices)):\n",
    "        if i != len(indices)-1:\n",
    "            splits.append((structures[i], s[indices[i]+len(structures[i]): indices[i+1]]))\n",
    "        else:\n",
    "            splits.append((structures[i], s[indices[i]+len(structures[i]):]))\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Songs to Analyze\n",
    "\n",
    "Read in the resulting dataframes from the spotify_analysis notebook, which were created as follows:\n",
    "\n",
    " - Started with the top five tracks for each of country, R&B/hip-hop, and rock/alternative as of the week of May 15, 2021, based on Billboard Top 100 charts (referred to as the \"seed tracks\")\n",
    " - Used Spotify's recommender algorithm to find the most similar songs to the seed tracks (returns a maximum of 100 songs per search)\n",
    " - Ranked the most similar songs by audio features using Euclidean distance\n",
    " - Fed the top ranking songs through Spotify's recommender algorithm until there were at least 1,000 songs per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country\n",
    "df_cty = pd.read_csv('../Data/df_cty.csv')\n",
    "df_cty.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rock/alternative\n",
    "df_rock = pd.read_csv('../Data/df_rock.csv')\n",
    "df_rock.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Lyrics from Genius API\n",
    "\n",
    "Pull lyrics from the Genius API with the lyricsgenius wrapper and put into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE BEER by HIXTAPE is not available\n",
      "Cowboy Killer by Ian Munsick is not available\n",
      "Before He Cheats by Carrie Underwood is not available\n",
      "Hotel Room by Do Or Die is not available\n",
      "Dusa by FL Dusa is not available\n",
      "Two Pina Coladas by Brooks Jefferson is not available\n"
     ]
    }
   ],
   "source": [
    "#country\n",
    "df_cty_lyrics = get_df_songs(df_cty['track'],df_cty['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back Door Santa by The Black Crowes is not available\n",
      "Welcome To The War by 7kingZ is not available\n",
      "White Rabbit by Egypt Central is not available\n",
      "2L8 by Ryan Oakes is not available\n",
      "The Shower Scene by Ice Nine Kills is not available\n",
      "Oh Betty by Fantastic Negrito is not available\n",
      "Stand And Deliver by Goodbye June is not available\n",
      "Moon Over the Castle by Bring Me The Horizon is not available\n",
      "Ti**ies by Krizz Kaliko is not available\n"
     ]
    }
   ],
   "source": [
    "#rock\n",
    "df_rock_lyrics = get_df_songs(df_rock['track'],df_rock['artist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Preprocess Lyrics\n",
    "\n",
    "Prepare lyrics for analysis by cleaning and normalizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows without lyrics\n",
    "df_cty_lyrics2 = df_cty_lyrics.dropna(subset=['lyrics']) #country\n",
    "df_rock_lyrics2 = df_rock_lyrics.dropna(subset=['lyrics']) #rock/alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/qnfbs7f539d_d_vxqj6lwsdr0000gn/T/ipykernel_53479/3095339618.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[new_col] = df[new_col].str.replace(r'\\n',' ') #replace '\\n' character with space\n",
      "/var/folders/2v/qnfbs7f539d_d_vxqj6lwsdr0000gn/T/ipykernel_53479/3095339618.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[new_col] = df[new_col].str.replace(r'\\[[^\\[\\]]*]','') #remove brackets and inside text\n",
      "/var/folders/2v/qnfbs7f539d_d_vxqj6lwsdr0000gn/T/ipykernel_53479/3095339618.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[new_col] = df[new_col].str.replace(r\"\\'\\w*\",'').str.replace(r'[^\\w\\d\\s]+','') #remove extra characters\n"
     ]
    }
   ],
   "source": [
    "#clean lyrics\n",
    "df_cty_cleaned = clean_lyrics(df_cty_lyrics2,'lyrics','words') #country\n",
    "df_rock_cleaned = clean_lyrics(df_rock_lyrics2,'lyrics','words') #rock/alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize lyrics\n",
    "df_cty_norm = normalize_lyrics(df_cty_cleaned,'words') #country\n",
    "df_rock_norm = normalize_lyrics(df_rock_cleaned,'words') #rock/alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_segments = []\n",
    "for lyrics in df_rock_norm['lyrics']:\n",
    "    rock_segments.append(segmenting(lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cty_segments = []\n",
    "for lyrics in df_cty_norm['lyrics']:\n",
    "    cty_segments.append(segmenting(lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock_norm['segments'] = rock_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cty_norm['segments'] = cty_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Dataframes to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country\n",
    "df_cty_norm.to_csv('../Data/df_cty_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rock/alternative\n",
    "df_rock_norm.to_csv('../Data/df_rock_lyrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
